parameters:
    # Common hyperparameters
    mode: 'train'
    load: false
    name: 'model3_pong'
    algorithm: PPO
    port: 8000
    gui: false
    env_type: 'atari' # 'atari', 'SUMO', or 'gridworld'
    scene: 'PongNoFrameskip-v4'
    flicker: false
    max_steps: 1.0e+7
    max_episode_steps: 5.0e+3
    num_frames: 1
    skip_frames: 4
    num_epoch: 3
    gamma: 0.99
    lambda: 0.95
    learning_rate: 2.5e-4
    batch_size: 32 # THIS NEEDS TO BE SMALLER THAN n_sequences = memory_size // seq_len
    memory_size: 128
    train_frequency: 1
    save_frequency: 1.0e+5
    summary_frequency: 5.0e+4
    tensorboard: true
    iteration: -1
    episode: 0
    # Bounding box
    box_height: 84
    box_width: 84
    box_center: [0, 0]
    frame_height: 84
    frame_width: 84

    # MAIN MODEL
    # Fully connected module
    fully_connected: false
    num_fc_layers: 1
    num_fc_units: [512]
    # Convolutional module
    convolutional: true
    num_conv_layers: 3
    num_filters: [32, 64, 64]
    kernel_sizes: [8, 4, 3]
    strides: [4, 2, 1]
    # Recurrent module
    recurrent: true
    num_rec_units: 256
    seq_len: 4

    # INFLUENCE MODEL
    influence: false
    inf_box_height: 84
    inf_box_width: 84
    inf_box_center: [[0, 0]]
    inf_frame_height: 84
    inf_frame_width: 84
    inf_num_frames: 1
    inf_num_predictors: 1
    # Influence fully connected module
    inf_num_fc_layers: 0
    inf_num_fc_units: [128]
    # Influence convolutional module
    inf_num_conv_layers: 3
    inf_num_filters: [32, 64, 64]
    inf_kernel_sizes: [8, 3, 2]
    inf_strides: [4, 2, 1]
    # Influence recurrent module
    inf_num_rec_units: 512
    inf_seq_len: 4

    # PPO only
    num_workers: 8
    beta: 1.0e-2
    epsilon: 0.1
    time_horizon: 128
    c1: 0.5
