parameters:
    # Common hyperparameters
    mode: 'train'
    load: false
    name: 'automatic_dpatch'
    algorithm: PPO
    port: 8000
    gui: false
    env_type: 'sumo' # 'atari', 'SUMO', or 'gridworld'
    scene: 'loop_network'
    flicker: false
    max_steps: 1.0e+6
    max_episode_steps: 5.0e+3
    num_frames: 1
    num_epoch: 3
    gamma: 0.99
    lambda: 0.95
    learning_rate: 2.5e-4
    batch_size: 32
    memory_size: 128
    train_frequency: 1
    save_frequency: 2.5e+4
    summary_frequency: 1.0e+4
    tensorboard: true
    iteration: -1
    episode: 0
    frame_height: 84 
    frame_width: 84

    # MAIN MODEL
    # Fully connected module
    fully_connected: true
    num_fc_layers: 1
    num_fc_units: [128]
    # Convolutional module
    convolutional: true
    num_conv_layers: 2
    num_filters: [16, 32]
    kernel_sizes: [4, 3]
    strides: [4, 3]
    # Recurrent module
    recurrent: false

    # INFLUENCE MODEL
    influence: true
    # Attention
    attention: false
    automatic_dpatch: true
    temperature: 1.0
    manual_dpatch: false
    inf_num_predictors: 2
    # Influence fully connected module
    inf_num_fc_layers: 0
    inf_num_fc_units: [128]
    # Influence recurrent module
    inf_num_rec_units: 128
    inf_seq_len: 32

    # PPO only
    num_workers: 1
    beta: 1.0e-2
    epsilon: 0.1
    time_horizon: 128
    c1: 1
