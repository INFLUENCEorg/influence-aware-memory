parameters:
    # Common hyperparameters
    mode: 'train'
    load: false
    name: 'manual_dpatch'
    algorithm: PPO
    port: 8000
    gui: false
    env_type: 'sumo' # 'atari', 'SUMO', or 'gridworld'
    scene: 'loop_network'
    flicker: false
    max_steps: 2.0e+6
    max_episode_steps: 5.0e+3
    num_frames: 1
    num_epoch: 4
    gamma: 0.99
    lambda: 0.95
    learning_rate: 2.5e-4
    batch_size: 128
    memory_size: 512
    train_frequency: 1
    save_frequency: 2.5e+4
    summary_frequency: 1.0e+4
    tensorboard: true
    iteration: -1
    episode: 0
    frame_height: 84
    frame_width: 84

    # MAIN MODEL
    # Fully connected module
    fully_connected: true
    num_fc_layers: 1
    num_fc_units: [128]
    # Convolutional module
    convolutional: true
    num_conv_layers: 3
    num_filters: [32, 64, 64]
    kernel_sizes: [8, 4, 3]
    strides: [4, 2, 1]
    # Recurrent module
    recurrent: false

    # INFLUENCE MODEL
    influence: true
    # Attention
    attention: false
    automatic_dpatch: false
    manual_dpatch: true
    # This boxes now refer to the output of the last conv layer (Check how to manually compute this)
    inf_box_height: [1, 1]
    inf_box_width: [1, 1]
    inf_box_center: [[6, 3], [3, 6]]
    inf_num_predictors: 2
    # Influence fully connected module
    inf_num_fc_layers: 0
    inf_num_fc_units: [128]
    # Influence recurrent module
    inf_num_rec_units: 128
    inf_seq_len: 32

    # PPO only
    num_workers: 1
    beta: 5.0e-3
    epsilon: 0.2
    time_horizon: 128
    c1: 1
